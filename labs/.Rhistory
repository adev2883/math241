library(knitr)
library(tidyverse)
library(gridExtra)
library(bayesrules)
library(rstan)
library(bayesplot)
library(gridExtra)
plot_gamma_poisson(shape = 400, rate = 80, sum_y = sum(c(7, 3, 8, 9, 10, 12)), n = 6)
#prior probability of going down
pnorm(0, mean = 7.2, sd = 2.6)
#prior probability of going up more than 8
1 - pnorm(8, mean = 7.2, sd = 2.6)
observed_changes <- c(-0.7, 1.2, 4.5, -4)
posterior_variance <- 1 / (1/2.6^2 + 4/2^2)
posterior_mean <- (7.2/2.6^2 + 4 * mean(observed_changes)/2^2) * posterior_variance
posterior_mean
posterior_variance
#posterior probability of going down
pnorm(0, mean = posterior_mean, sd = sqrt(posterior_variance))
#posterior probability of going up more than 8
1 - pnorm(8, mean = posterior_mean, sd = sqrt(posterior_variance))
# Define the grid values for mu
mu_grid <- seq(5, 15, by = 1)
# Prior distribution parameters
mu_prior_mean <- 10
mu_prior_sd <- 1.2
y_sd <- 1.3
# Observed data
data <- c(7.1, 8.9, 8.4, 8.6)
# Calculate the prior at each grid point
prior <- dnorm(mu_grid, mean = mu_prior_mean, sd = mu_prior_sd)
# Calculate the likelihood at each grid point
likelihood <- sapply(mu_grid, function(mu) {
prod(dnorm(data, mean = mu, sd = y_sd))
})
# Calculate the unnormalized posterior
unnormalized_posterior <- prior * likelihood
# Normalize the posterior
posterior <- unnormalized_posterior / sum(unnormalized_posterior)
# Create the histogram visualization of the posterior
barplot(height = posterior, names.arg = mu_grid, main = "Posterior for μ with Grid Approximation")
# Set the number of grid points
k <- 11
# Create a sequence of mu grid values from 5 to 15
mu_grid <- seq(from=5, to=15, length.out=k)
# Calculate the prior probability using the Normal distribution
prior <- dnorm(mu_grid, mean=10, sd=1.2)
# Calculate the likelihood for each observed data point
likelihood <- sapply(mu_grid, function(mu) {
dnorm(c(7.1, 8.9, 8.4, 8.6), mean=mu, sd=1.3)
})
# Calculate the product of the prior and likelihood for the unnormalized posterior
unnormalized <- apply(likelihood, 2, prod) * prior
# Normalize the posterior
normalized <- unnormalized / sum(unnormalized)
# Sample from the grid for the grid approximation
grid_approx <- sample(x=mu_grid, size=10000, prob=normalized, replace=TRUE)
# Plot the histogram of the grid approximation
hist(grid_approx, breaks=50, main="Histogram of Grid Approximation for Posterior of μ")
# Set the number of grid points
k <- 11
# Create a sequence of mu grid values from 5 to 15
mu_grid <- seq(from=5, to=15, length.out=k)
# Calculate the prior probability using the Normal distribution
prior <- dnorm(mu_grid, mean=10, sd=1.2)
# Calculate the likelihood for each observed data point
likelihood <- sapply(mu_grid, function(mu) {
dnorm(c(7.1, 8.9, 8.4, 8.6), mean=mu, sd=1.3)
})
# Calculate the product of the prior and likelihood for the unnormalized posterior
unnormalized <- apply(likelihood, 2, prod) * prior
# Normalize the posterior
normalized <- unnormalized / sum(unnormalized)
# Sample from the grid for the grid approximation
grid_approx <- sample(x=mu_grid, size=10000, prob=normalized, replace=TRUE)
# Convert to data frame for ggplot
grid_approx_df <- data.frame(mu = grid_approx)
# Use ggplot2 to plot the histogram
ggplot(grid_approx_df, aes(x=mu)) +
geom_histogram(bins=50, fill="blue", color="black") +
labs(title="Histogram of Grid Approximation for Posterior of μ", x="μ", y="Frequency")
k <- 201
# Create a sequence of mu grid values from 5 to 15, now with 201 points
mu_grid <- seq(from=5, to=15, length.out=k)
# Calculate the prior probability using the Normal distribution
prior <- dnorm(mu_grid, mean=10, sd=1.2)
# Calculate the likelihood for each observed data point
likelihood <- sapply(mu_grid, function(mu) {
dnorm(c(7.1, 8.9, 8.4, 8.6), mean=mu, sd=1.3)
})
# Calculate the product of the prior and likelihood for the unnormalized posterior
unnormalized <- apply(likelihood, 2, prod) * prior
# Normalize the posterior
normalized <- unnormalized / sum(unnormalized)
# Sample from the grid for the grid approximation
grid_approx <- sample(x=mu_grid, size=10000, prob=normalized, replace=TRUE)
# Plot the histogram of the grid approximation with more refined grid
hist(grid_approx, breaks=50, main="Histogram of Fine Grid Approximation for Posterior of μ")
k <- 11
mu_grid <- seq(from=5, to=15, length.out=k)
prior <- dnorm(mu_grid, mean=10, sd=1.2)
likelihood <- sapply(mu_grid, function(mu) {
dnorm(c(7.1, 8.9, 8.4, 8.6), mean=mu, sd=1.3)
})
unnormalized <- apply(likelihood, 2, prod) * prior
normalized <- unnormalized / sum(unnormalized)
grid_approx <- sample(x=mu_grid, size=10000, prob=normalized, replace=TRUE)
hist(grid_approx, breaks=50)
k <- 201
mu_grid <- seq(from=5, to=15, length.out=k)
prior <- dnorm(mu_grid, mean=10, sd=1.2)
likelihood <- sapply(mu_grid, function(mu) {
dnorm(c(7.1, 8.9, 8.4, 8.6), mean=mu, sd=1.3)
})
unnormalized <- apply(likelihood, 2, prod) * prior
normalized <- unnormalized / sum(unnormalized)
grid_approx <- sample(x=mu_grid, size=10000, prob=normalized, replace=TRUE)
hist(grid_approx, breaks=50)
stan_model <- "
data {
int<lower=0> n;
vector[n] Y;
}
parameters {
real mu;
}
model {
mu ~ normal(10, 1.2);
Y ~ normal(mu, 1.3);
}
"
data_list <- list(n = 4, Y = c(7.1, 8.9, 8.4, 8.6))
fit <- stan(model_code = stan_model, data = data_list,
iter = 10000, chains = 4)
print(fit)
stan_model <- "
data {
int<lower=0> n;
vector[n] Y;
}
parameters {
real mu;
}
model {
mu ~ normal(10, 1.2);
Y ~ normal(mu, 1.3);
}
"
data_list <- list(n = 4, Y = c(7.1, 8.9, 8.4, 8.6))
fit <- stan(model_code = stan_model, data = data_list,
iter = 10000, chains = 4)
fit
# Load the bayesplot library for visualization
library(bayesplot)
# Generate trace plots
mcmc_trace(fit)
# Generate density plots
mcmc_dens(fit)
data("pulse_of_the_nation",package="bayesrules")
force(pulse_of_the_nation)
View(pulse_of_the_nation)
stan_model_code <- "
data {
int<lower=0> n;
int<lower=0> Y[n];
}
parameters {
real<lower=0> lambda;
}
model {
lambda ~ gamma(20, 5);
Y ~ poisson(lambda);
}
"
data_list <- list(n = 3, Y = c(0, 1, 0))
fit <- stan(model_code = stan_model_code, data = data_list,
iter = 10000, chains = 4)
stan_model_2 <- "
data {
int<lower=0> n;
int<lower=0> Y[n];
}
parameters {
real<lower=0> lambda;
}
model {
lambda ~ gamma(20, 5);
Y ~ poisson(lambda);
}
"
data_list2 <- list(n = 3, Y = c(0, 1, 0))
fit2 <- stan(model_code = stan_model_2, data = data_list2,
iter = 10000, chains = 4)
fit2
mcmc_trace(fit2)
mcmc_dens(fit2)
alpha_a <- 0.4
pi_lower <- qbeta(alpha_a / 2, 4, 5)
pi_upper <- qbeta(1 - alpha_a / 2, 4, 5)
c(pi_lower, pi_upper)
alpha_b <- 0.01
lambda_lower <- qgamma(alpha_b / 2, 1, 5)
lambda_upper <- qgamma(1 - alpha_b / 2, 1, 5)
c(lambda_lower, lambda_upper)
alpha_c <- 0.2
mu_lower <- qnorm(alpha_c / 2, -3, 1)
mu_upper <- qnorm(1 - alpha_c / 2, -3, 1)
c(mu_lower, mu_upper)
data("pulse_of_the_nation", package = "bayesrules")
# Assuming 'climate_change' is a variable in the dataset and 'Not Real At All' is a response
sample_proportion <- mean(pulse_of_the_nation$climate_change == 'Not Real At All')
sample_proportion
data("pulse_of_the_nation", package = "bayesrules")
# Assuming 'climate_change' is a variable in the dataset and 'Not Real At All' is a response
sample_prop <- mean(pulse_of_the_nation$climate_change == 'Not Real At All')
sample_prop
num_success <- sum(pulse_of_the_nation$climate_change == 'Not Real At All')
num_failure <- nrow(pulse_of_the_nation) - num_success
# Update the prior to get the posterior parameters
alpha_post <- 1 + num_success
beta_post <- 2 + num_failure
# Calculate the middle 95% credible interval
ci_lower <- qbeta(0.025, alpha_post, beta_post)
ci_upper <- qbeta(0.975, alpha_post, beta_post)
c(ci_lower, ci_upper)
num_success <- sum(pulse_of_the_nation$climate_change == 'Not Real At All')
num_failure <- nrow(pulse_of_the_nation) - num_success
# Update the prior to get the posterior parameters
alpha_post <- 1 + num_success
beta_post <- 2 + num_failure
# Calculate the middle 95% credible interval
ci_lower <- qbeta(0.025, alpha_post, beta_post)
ci_upper <- qbeta(0.975, alpha_post, beta_post)
c(ci_lower, ci_upper)
alpha_post
beta_post
num_success <- sum(pulse_of_the_nation$climate_change == 'Not Real At All')
num_failure <- nrow(pulse_of_the_nation) - num_success
alpha_post <- 1 + num_success
beta_post <- 2 + num_failure
ci_lower <- qbeta(0.025, alpha_post, beta_post)
ci_upper <- qbeta(0.975, alpha_post, beta_post)
c(ci_lower, ci_upper)
alpha_post
beta_post
num_success <- sum(pulse_of_the_nation$climate_change == 'Not Real At All')
num_failure <- nrow(pulse_of_the_nation) - num_success
1+num_success
2+num_failure
alpha_post <- 1 + num_success
beta_post <- 2 + num_failure
ci_lower <- qbeta(0.025, alpha_post, beta_post)
ci_upper <- qbeta(0.975, alpha_post, beta_post)
c(ci_lower, ci_upper)
alpha_post
beta_post
num_success <- sum(pulse_of_the_nation$climate_change == 'Not Real At All')
num_failure <- nrow(pulse_of_the_nation) - num_success
1+num_success
2+num_failure
alpha_post <- 151
beta_post <- 852
ci_lower <- qbeta(0.025, alpha_post, beta_post)
ci_upper <- qbeta(0.975, alpha_post, beta_post)
c(ci_lower, ci_upper)
alpha_post
beta_post
num_success <- sum(pulse_of_the_nation$climate_change == 'Not Real At All')
num_failure <- nrow(pulse_of_the_nation) - num_success
1+num_success
2+num_failure
alpha_post <- 151
beta_post <- 852
ci_lower <- qbeta(0.025, alpha_post, beta_post)
ci_upper <- qbeta(0.975, alpha_post, beta_post)
c(ci_lower, ci_upper)
post_prob_Ha <- 1 - pbeta(0.1, alpha_post, beta_post)
post_prob_Ha
# Define the Stan model
stan_model3 <- "
data {
int<lower=0> successes;
int<lower=0> trials;
}
parameters {
real<lower=0, upper=1> pi;
}
model {
pi ~ beta(151, 852); // Use the alpha_post and beta_post values from part c
successes ~ binomial(trials, pi);
}
"
# Prepare data for Stan model - using the number of successes and trials
data_list3 <- list(successes = 151, trials = 1003) # Replace with actual values
# Run the MCMC simulation with 4 chains and 1000 iterations per chain
fit3 <- stan(model_code = stan_model3, data = data_list3,
iter = 1000, chains = 4, control = list(adapt_delta = 0.95))
# Generate trace plots
traceplot(fit3)
# Generate density plots
densityplot(fit3)
library(rstan)
library(bayesplot)
stan_model3 <- "
data {
int<lower=0> successes;
int<lower=0> trials;
}
parameters {
real<lower=0, upper=1> pi;
}
model {
pi ~ beta(151, 852); // Use the alpha_post and beta_post values from part c
successes ~ binomial(trials, pi);
}
"
# Prepare data for Stan model - using the number of successes and trials
data_list3 <- list(successes = 151, trials = 1003) # Replace with actual values
# Run the MCMC simulation with 4 chains and 1000 iterations per chain
fit3 <- stan(model_code = stan_model3, data = data_list3,
iter = 1000, chains = 4, control = list(adapt_delta = 0.95))
# Generate trace plots
traceplot(fit3)
# Generate density plots
densityplot(fit3)
library(rstan)
library(bayesplot)
stan_model3 <- "
data {
int<lower=0> successes;
int<lower=0> trials;
}
parameters {
real<lower=0, upper=1> pi;
}
model {
pi ~ beta(151, 852); // Use the alpha_post and beta_post values from part c
successes ~ binomial(trials, pi);
}
"
# Prepare data for Stan model - using the number of successes and trials
data_list3 <- list(successes = 151, trials = 1003) # Replace with actual values
# Run the MCMC simulation with 4 chains and 1000 iterations per chain
fit3 <- stan(model_code = stan_model3, data = data_list3,
iter = 1000, chains = 4, control = list(adapt_delta = 0.95))
# Generate trace plots
traceplot(fit3)
# Generate density plots
mcmc_dens(fit3)
# Report the effective sample size ratio and R-hat values
ess_ratio <- summary(fit3)$summary[,'n_eff'] / summary(fit3)$summary[,'n_iter']
library(rstan)
library(bayesplot)
stan_model3 <- "
data {
int<lower=0> successes;
int<lower=0> trials;
}
parameters {
real<lower=0, upper=1> pi;
}
model {
pi ~ beta(151, 852); // Use the alpha_post and beta_post values from part c
successes ~ binomial(trials, pi);
}
"
# Prepare data for Stan model - using the number of successes and trials
data_list3 <- list(successes = 151, trials = 1003) # Replace with actual values
# Run the MCMC simulation with 4 chains and 1000 iterations per chain
fit3 <- stan(model_code = stan_model3, data = data_list3,
iter = 1000, chains = 4, control = list(adapt_delta = 0.95))
# Generate trace plots
mcmc_trace(fit3)
# Generate density plots
mcmc_dens(fit3)
# Report the effective sample size ratio and R-hat values
ess_ratio <- summary(fit3)$summary[,'n_eff'] / summary(fit3)$summary[,'n_iter']
library(rstan)
library(bayesplot)
stan_model3 <- "
data {
int<lower=0> successes;
int<lower=0> trials;
}
parameters {
real<lower=0, upper=1> pi;
}
model {
pi ~ beta(151, 852); // Use the alpha_post and beta_post values from part c
successes ~ binomial(trials, pi);
}
"
data_list3 <- list(successes = 151, trials = 1003)
fit3 <- stan(model_code = stan_model3, data = data_list3,
iter = 1000, chains = 4, control = list(adapt_delta = 0.95))
mcmc_trace(fit3)
mcmc_dens(fit3)
ess <- summary(fit3)$summary[,'n_eff']  # Extract effective sample size
rhat_values <- summary(fit3)$summary[,'Rhat']  # Extract R-hat values
list(ess_ratio = ess_ratio, rhat_values = rhat_values)
library(rstan)
library(bayesplot)
stan_model3 <- "
data {
int<lower=0> successes;
int<lower=0> trials;
}
parameters {
real<lower=0, upper=1> pi;
}
model {
pi ~ beta(151, 852); // Use the alpha_post and beta_post values from part c
successes ~ binomial(trials, pi);
}
"
data_list3 <- list(successes = 151, trials = 1003)
fit3 <- stan(model_code = stan_model3, data = data_list3,
iter = 1000, chains = 4, control = list(adapt_delta = 0.95))
mcmc_trace(fit3)
mcmc_dens(fit3)
ess <- summary(fit3)$summary[,'n_eff']  # Extract effective sample size
rhat_values <- summary(fit3)$summary[,'Rhat']  # Extract R-hat values
# Since we know the number of iterations, we can directly use that number
n_iter <- 1000
# Calculate the effective sample size ratio
ess_ratio <- ess / n_iter
# Compile the diagnostics into a list
diagnostics <- list(ess_ratio = ess_ratio, rhat_values = rhat_values)
# Print the diagnostics
print(diagnostics)
library(rstan)
library(bayesplot)
stan_model3 <- "
data {
int<lower=0> successes;
int<lower=0> trials;
}
parameters {
real<lower=0, upper=1> pi;
}
model {
pi ~ beta(151, 852); // Use the alpha_post and beta_post values from part c
successes ~ binomial(trials, pi);
}
"
data_list3 <- list(successes = 151, trials = 1003)
fit3 <- stan(model_code = stan_model3, data = data_list3,
iter = 1000, chains = 4, control = list(adapt_delta = 0.95))
mcmc_trace(fit3)
mcmc_dens(fit3)
ess <- summary(fit3)$summary[,'n_eff']  # Extract effective sample size
rhat_values <- summary(fit3)$summary[,'Rhat']  # Extract R-hat values
# Since we know the number of iterations, we can directly use that number
n_iter <- 1000
# Calculate the effective sample size ratio
ess_ratio <- ess / n_iter
# Compile the diagnostics into a list
diagnostics <- list(ess_ratio = ess_ratio, rhat_values = rhat_values)
diagnostics
pi_samples <- extract(fit3)$pi
Y_prime_samples <- rbinom(1000, size = 100, prob = pi_samples)
hist(Y_prime_samples, breaks = 30, main = "Posterior Predictive Distribution of Y'")
prob_at_least_20 <- mean(Y_prime_samples >= 20)
prob_at_least_20
# Do not modify this chunk.
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
# Put all necessary libraries here
library(tidyverse)
library(rnoaa)
library(rvest)
library(httr)
library(dplyr)
library(tidyverse)
# Don't forget to install it first!
library(rnoaa)
options(noaakey = "mEqPbHQRJEpSMWZAMXLxLNawcEsSkMUR")
stations <- ncdc_stations(datasetid = "GHCND",
locationid = "FIPS:41051")
mult_stations <- stations$data
nrow(mult_stations)
# First fill-in and run to following to determine the
# datatypeid
year <- 2023
# specifying the datatypeid for precipitation, and including startdate and enddate
precip_se_pdx <- ncdc(datasetid = "GHCND",
stationid = "GHCND:US1ORMT0006",
datatypeid = "PRCP",
startdate = paste0(year, "-01-01"),
enddate = paste0(year, "-01-31"),
limit = 1000)
precip_se_pdx_data <- precip_se_pdx$data
precip_se_pdx_data$date <- ymd_hms(precip_se_pdx_data$date)
ggplot(precip_se_pdx_data, aes(x = date, y = value)) +
geom_line() +
geom_point() + # adds points to lines
labs(title = "Daily Precipitation in Portland for January",
x = "Date",
y = "Precipitation (in hundredths of inches)") +
theme_minimal()
# Install and load rfishbase
install.packages("rfishbase")
library(rfishbase)
# Install and load ggplot2 for plotting
install.packages("ggplot2")
library(ggplot2)
# A selection of fish species
species_list <- c("Gadus morhua", "Oncorhynchus mykiss", "Salmo trutta")
# Fetch length data for each species
length_data <- lapply(species_list, function(species) {
data <- species(species)
data.frame(Species = species, Length = as.numeric(data$Length))
})
